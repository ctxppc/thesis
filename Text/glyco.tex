\documentclass[main.tex]{subfiles}
\begin{document}
\onlyinsubfile{\mainmatter{}}

\chapter{Glyco: A Nanopass Compiler for CHERI-RISC-V}
Glyco\footnote{From the Greek term $\gamma\lambda\upsilon\kappa{}o$ meaning \enquote{sweet}, alluding to the taste of a wild cherry.} is a compiler targeting the CHERI-RISC-V architecture, producing software running on CheriBSD systems and on a Sail-based emulator of the CHERI-RISC-V ISA.

We begin this chapter in \cref{sct:nanopass} by giving a concise description of the nanopass compiler design used by Glyco, an iterative approach to designing and implementing a compiler that results in a series of transformations of a program from a high-level language to a low-level language (such as assembly) via several intermediate languages.

In \cref{sct:ex} we discuss the high-level language EX, a functional programming language with support for common features such as functions, conditionals, definitions, vectors, and records. These features are implemented in several transformations from EX to the CC language.

\Cref{sct:cc} deals with CC, a procedural programming language with support for procedures, variables, conditionals, vectors, and records. It is also the highest-level language in Glyco that supports the notion of a procedure with parameters and results. CC programs are transformed to SV programs by imposing a set of rules governing procedure calls, i.e., a calling convention.

SV is a structured imperative programming language with support for variables, conditionals, vectors, and records, and is discussed in \cref{sct:sv}. SV programs are transformed to ID programs by substituting indices and fields with byte offsets.

ID, AL, and ALA are three structured imperative languages with support for variables and conditionals; all three are discussed in \cref{sct:id}. ID programs don't need to declare local variables whereas AL programs do need to declare them. The transformation between the two languages performs a basic inference algorithm to discover the names and types of variables. AL programs are then \lowered{} to ALA programs which contain additional liveness and conflict information. This information is then used to perform register allocation and assign a register or memory location to each variable, resulting in a CD program.

In \cref{sct:cd} we go over CD, a structured imperative language with support for conditionals. CD programs are flattened over several passes to FO programs, which consists of labelled and unlabelled effects in a similar way to labelled and unlabelled instructions in an assembly program. We then tackle the last few transformations in \cref{sct:fo} before getting an assembly program.

This chapter discusses the feature set and languages of Glyco 0.1,\footnote{The source code is available at \url{https://tsarouhas.eu/glyco/0.1/}.} which allows us to focus in each chapter on one set of functionality. It also permits us to evaluate how the nanopass approach performs with extensions in future versions which we discuss in later chapters.

Example programs in this chapter follow the grammar of the final version of the compiler, Glyco 1.0,\footnote{The source code is available at \url{https://tsarouhas.eu/glyco/1.0/}.} and are compiled using the default configuration. The syntax of a program in one compiler version does not significantly change in another version but for consistency we chose to express all programs in the latest compiler's syntax, skipping languages introduced after Glyco 0.1. A full language reference of this syntax can be found in \cref{ch:grammar}. 

\section{Background: Nanopass Compilers} \label{sct:nanopass}
Glyco is built following a \emph{nanopass} compiler design, described in the context of compiler education by several authors such as \cite{educomp} and in the context of commercial compiler development by authors such as \cite{commcomp}. A nanopass compiler consists of numerous small passes, so-called \textbf{\glspl{nanopass}}, which translate programs written in one \textbf{\g{il}} to programs written in another. The input of a \g{nanopass} is a program in a higher-level language than the one of its output; we therefore call this translation process a \textbf{\g{lowering}}. A \g{nanopass} should be concise and perform a relatively self-contained transformation. There should be no data structures shared across \gs{nanopass} except for the program itself.

The nanopass design allows the compiler engineer to design and implement their compiler \emph{by iterated abstraction}. A simplified description follows. The engineer first chooses a target language (usually a machine language such as x86-64 or indeed CHERI-RISC-V) and determines an abstraction over it. The engineer then defines an \g{il} that implements that abstraction as well as a \gls{nanopass} which transforms programs written in the new \g{il} to the target language. The compiler engineer then repeats this process, this time abstracting over the \g{il} with a new \g{il} and \gls{nanopass}. This process goes on until a level of abstraction has been reached that can either be directly used as a source language (by human users), or be easily produced by parser actions.

An important benefit of the nanopass approach is each new iteration begins and ends with a working compiler. After each iteration, users can start writing and compiling programs in the new \g{il} and unit tests can be written that ensure that the new \gls{nanopass} produces the expected transformations. For experimental architectures such as CHERI-RISC-V, this also means that designers can experiment more quickly with new ideas, something that may be harder to do on a full-fledged production compiler such as Clang.

Glyco 0.1 defines 20 \gs{il}, with a general approach adapted from the student compiler by \cite{compcourse}. Each language is usually named after the new abstraction or feature it brings compared to the \g{lowerlang}. We discuss the \gs{il} in reverse chronological order (from high-level to low-level languages) as opposed to the order in which the \gs{il} were defined (from low-level to high-level languages). This allows us to explain the compiler pipeline using example programs, showing how they are manipulated by the compiler's \gs{nanopass}.

\section{An Expression Language} \label{sct:ex}
The highest \g{il} in the first version of Glyco is called \textbf{EX} (Expressions), a language with basic support for arithmetic operations, functions, conditionals (\texttt{if}-\texttt{then}-\texttt{else}), definitions (\texttt{let}-bindings), vectors (fixed-size arrays), and records (collections of key-value pairs).

The following EX program computes the 30th number in the Fibonacci sequence starting with 0 and 1:
\lstinputlisting{Programs/fib.ex}

This program defines a function \texttt{fib} with three signed 32-bit integer parameters \texttt{prev}, \texttt{curr}, and \texttt{iter} and which returns a signed 32-bit integer. The function recursively adds the \enquote{previous} and \enquote{current} sums until the number of iterations drops to 0, then returns the \enquote{current} sum. The program itself is defined as the result of \texttt{fib} where \texttt{prev} is 0, \texttt{curr} is 1, and \texttt{iter} is 30.

EX is an \emph{intermediate} language and not necessarily a \emph{user-friendly} language; it is instead quite explicit and contains little syntactical sugar. For example, a value representing the constant 30 is written as \texttt{constant(30)}, the value of a variable or parameter named \texttt{iter} is written as \texttt{named(iter)}, and the predicate $ \textit{iter} \le 0 $ is written as \texttt{relation(named(iter), le, constant(0))}. A significant benefit is that the structure is easy to manipulate as the code goes through the compiler's \gs{nanopass}. One can, however, define a more user-friendly language and write a parser that emits EX.

\paragraph{From EX (Expressions) to LS} LS does not support subexpressions so the \g{nanopass} to LS binds all subexpressions to names (temporaries) and uses those names in place of the subexpressions. For instance, the EX value
\begin{lstlisting}
	evaluate(function(fib), ... binary(named(prev), add, named(curr)) ...)
\end{lstlisting}
is transformed into the equivalent LS value
\begin{lstlisting}
	let(
		(arg0, ...) (arg1, let(
			(ex.lhs, source(named(prev))) (ex.rhs, source(named(curr))),
			in: binary(named(ex.lhs), add, named(ex.rhs))
		)) (arg2, ...),
		in: evaluate(fib, named(arg0) named(arg1) named(arg2))
	)
\end{lstlisting}

Some transformations are not strictly necessary, e.g., binding \texttt{named(prev)} to \texttt{ex.lhs} instead of using \texttt{named(prev)} directly. They do not however incur any additional overhead in the final executable: a \g{nanopass} further down the compiler pipeline cleans up these redundant temporaries.

\paragraph{From LS (Lexical Scopes) to DF} DF does not support shadowing; all \texttt{let} bindings are in a single namespace. The \g{nanopass} from LS to DF implements shadowing by renaming symbols such that each definition uses a globally unique symbol.

\paragraph{From DF (Definitions) to CV} CV does not support \texttt{let} bindings, i.e., definitions. The \g{nanopass} implements each definition in CV using a \texttt{do} value, i.e., a computed value, a value on which a computation can be attached, with a \texttt{set} effect in it. For example, the DF value
\begin{lstlisting}
	let((answer, source(constant(42))), in: source(location(answer)))
\end{lstlisting}
is \lowered{} to the CV value
\begin{lstlisting}
	do(set(answer, to: source(constant(42))), then: source(location(answer)))
\end{lstlisting}

\paragraph{From CV (Computed Values) to CA} CA does not support \texttt{do} \emph{values}, but does support \texttt{do} \emph{effects}, which are sequences of effects. The \g{nanopass} implements \texttt{do} values by extracting their effects into \texttt{do} effects and ending with an additional \texttt{set} effect that moves the result to the intended destination. That is, a CV \texttt{set} effect
\begin{lstlisting}
	set(result, to:
		do(
			/* effects */,
			then: /* result */
		)
	)
\end{lstlisting}
is transformed to a CA \texttt{do} effect
\begin{lstlisting}
	do(
		/* effects */
		set(result, to: /* result */)
	)
\end{lstlisting}

\paragraph{From CA (Canonical Assignments) to CC} The final purely structural transformation lowers \texttt{set} effects in CA using equivalent effects in CC, only keeping the \texttt{set} effects with a constant or location source. For example, the CA program
\lstinputlisting{Programs/values.ca}
is lowered to the CC program
\lstinputlisting{Programs/values.cc}

\section{A Conventional Calling Convention} \label{sct:cc}
A \g{cc} is a set of rules imposed by the operating system, instruction set architecture, and/or programming language that specify how procedures are called. A low-level \g{cc} often specifies
\begin{itemize}[noitemsep]
	\item where parameters and result values are placed (in dedicated registers, in a particular order on the call stack, or a combination of both);
	\item how large values are passed to the callee or caller (over multiple registers, on the call stack, or in heap memory), if supported;
	\item the state of the call stack and some registers (like the register keeping the frame pointer) when a procedure starts executing and when it returns to the caller;
	\item which registers a procedure can use freely but for which it cannot assume that their contents will be preserved across a procedure call (\textbf{\gs{cersaved}}); and
	\item which registers a procedure can only use after saving their previous contents and if they're restored after use (\textbf{\gs{ceesaved}}).
\end{itemize}

The \g{cc} used in the base version of Glyco is called \textbf{\g{gccc}} and mimics a traditional \g{cc} that would be used for programs written in C, with some parts specified by \cite[chapter~25]{riscv}.

\paragraph{Call stack} The call stack is a region of memory on which information about procedure calls is stored, such as local state and return addresses. The stack grows downward, i.e., from high to low addresses. The \texttt{csp} register contains the \textbf{\g{stackcap}}, a capability that points to the location of the last pushed datum, i.e., the top of the stack, and gives read-write authority over the stack memory. The \g{stackcap}'s address decreases whenever data are pushed to the call stack and increases whenever data are popped from the stack.

\paragraph{Call frames} A call frame (also known as a \emph{stack frame}) is a region of memory on the call stack that belongs to a procedure call and on which the procedure can store its local state. The \texttt{cfp} register contains the \textbf{\g{framecap}}, a capability derived from the \g{stackcap} that points to the base of the call frame. The procedure places local state and expects parameters in locations that are fixed distances removed from this base.

Before accessing its call frame, a procedure pushes a call frame of the desired size to the call stack in three steps. The procedure first pushes the (caller's) \g{framecap} to the call stack, then updates the \g{framecap} to point to this capability, and finally allocates room for its local state by moving the \g{stackcap} so that it points to the new call frame's last datum.

A procedure pops its call frame when it is done using it, e.g., when returning to its caller. It does so by popping all data stored in the call frame and restoring the previous \g{framecap}.

\paragraph{Parameters} Arguments to parameters are passed to the callee via dedicated argument registers first. When the set of argument registers is exhausted, any remaining arguments are pushed (in order) to the stack where they become part of the caller's call frame for the duration of the call.\footnote{This is the only part of another procedure's call frame that a callee is allowed to access directly.} Since these \emph{frame-resident} arguments reside at higher addresses than the callee's \g{framecap}, the callee can access these arguments using positive offsets of the \g{framecap}.

The set of argument parameters in Glyco is customisable via a command-line option. The default set is \texttt{a0}, \texttt{a1}, \texttt{a2}, \texttt{a3}, \texttt{a4}, \texttt{a5}, \texttt{a6}, and \texttt{a7}.

All of Glyco's supported data types in Glyco fit in a register. Vectors and records are passed by reference as capabilities.

\paragraph{Results} A procedure can return a single value via the \texttt{a0} register. Vectors and records are returned by reference as capabilities.

\paragraph{Available registers} The set of \gs{cersaved} and \gs{ceesaved} registers is customisable via command-line options. The default \gs{cersaved} are \texttt{s1}, \texttt{s2}, \texttt{s3}, \texttt{s4}, \texttt{s5}, \texttt{s6}, \texttt{s7}, \texttt{s8}, \texttt{s9}, \texttt{s10}, and \texttt{s11}; the default \gs{ceesaved} are the remaining 9 registers available in CC.

\paragraph{Local state} A procedure call's local state comprises saved register data (cf. supra), data for which no register is available, and stack-allocated buffers. These reside at lower addresses than the call's \g{framecap}; the procedure can therefore access them using negative offsets of the \g{framecap}.

\paragraph{Return address} The caller provides a return address capability in the \texttt{cra} register.\footnote{\texttt{cra} is a \g{ceesaved}, so if the callee needs to call another procedure, it will need to save the contents of \texttt{cra} before overwriting the register, except in the special case of a tail-call.} The callee can return control to the callee by jumping to this return capability.

\Cref{fig:gcccstack} shows a simple two-frame call stack example with zero registers available for arguments and local variables, to force Glyco to store them in call frames.

\begin{figure}
	\begin{center}
		\includegraphics{Images/GCCC Stack.pdf}
	\end{center}
	\caption{A call stack containing two call frames in a configuration of GCCC where no registers are available for storing parameters and local variables. The first call frame belongs to the initial procedure \texttt{main} which is called by the runtime, a dynamic linker, or the operating system and takes no parameters. Its call frame contains a \emph{previous frame pointer} capability that points to an unspecified location (possibly \texttt{null}) as well as two local variables \texttt{discount} and \texttt{price}. \texttt{main} invokes the 2-parameter \texttt{computeUnitPrice} procedure, binding the value \texttt{0.2} to the \texttt{discount} parameter and \texttt{cherry} to the \texttt{product} parameter. The latter procedure's call frame contains a \emph{previous frame pointer} capability that points to the location of the \emph{previous frame pointer} capability in the previous call frame, as well as a local variable \texttt{demand}. This call frame is at the top of the stack and so the \texttt{cfp} register's capability points to the \emph{previous frame pointer} capability in \texttt{computeUnitPrice}'s call frame. The \texttt{csp} register's capability always points to the last datum pushed on the stack, which is \texttt{demand} in this example. Note that the stack grows downward.}
	\label{fig:gcccstack}
\end{figure}

\hspace{0pt} \\
CC (Calling Convention) introduces procedures with parameters and results. It is \lowered{} to its \g{lowerlang} SV by imposing the \g{cc} described above. For example, the CC program
\lstinputlisting{Programs/42.cc}
is \lowered{} to the following SV program:
\lstinputlisting{Programs/42.sv}
\todo{Highlight corresponding parts.}

The CC to SV \g{nanopass} implements \g{cersaved} preservation by binding the registers' contents to temporary names before the call, and restores those registers' contents after the call. The register allocator down the compiler pipeline ensures that these temporaries are preserved across the call. % TODO: Remove those dead moves so that we can claim here that ALA will clean those redundant sets.

\section{Structured Values} \label{sct:sv}
The next \g{il}, \textbf{SV} (Structured Values) provides a structured abstraction over unstructured buffers in the form of vectors and records. A \textbf{vector} in SV is a homogeneous\footnote{All elements are of the same data type.} fixed-size\footnote{The number of elements is determined at creation and can only be changed by creating a new vector of the desired size and moving all elements to it.} array and is represented with a capability that points to the vector's first element, similarly to an array in the C programming language. A \textbf{record} is a heterogeneous\footnote{Values are not necessarily of the same data type.} key-value map with fixed keys and is similar to a C \texttt{struct}. However, unlike C \texttt{struct}s and like SV vectors, a record is represented with a capability that points to the record's first value. Vectors and records in SV are always passed by reference and never implicitly copied. Vector and record capabilities are automatically bounded to the region of memory they occupy; indexing a vector with an index that exceeds the vector's length causes a machine trap.\footnote{Due to CHERI-RISC-V bounds compression, a buffer capability may grant a larger region of memory than requested during allocation, meaning that some \enquote{out of bounds} indices near the end index may actually be valid and not cause a trap. Glyco compensates for this by allocating the extra memory granted by the buffer capability, thereby ensuring that no other buffer can occupy this extra space accessible by the first capability.}

Structured values are implemented in the \g{lowerlang} ID by translating effects dealing with them into effects dealing with unstructured data buffers. For example, the SV program
\lstinputlisting{Programs/sequences.sv}
is \lowered{} to the following ID program:
\lstinputlisting{Programs/sequences.id}
\todo{Highlight corresponding parts.}

The results of the \texttt{sll} (logical left shift) operations in this program are statically computed as part of an optimisation pass in a lower \g{il}.

\section{Abstract Locations} \label{sct:id}
All programs until now have been able to bind values to names in one form or another, be it by using new named locations in effects or binding values to names with \texttt{let}. These names refer to physical locations where data can be stored, but without the programmer explicitly specifying the physical location itself, and are therefore referred to as \textbf{abstract locations}. The compiler is responsible for assigning each abstract location a \textbf{physical location} like a register or location in the call frame.

Since registers are orders of magnitude faster to access than locations in RAM, the compiler attempts to assign as many abstract locations as it can to registers in a process called \textbf{register allocation}. Since the number of registers is limited, the compiler may need to \textbf{spill} abstract locations to locations on the call frame. Glyco employs several heuristics to minimise the runtime cost by spilling abstract locations that it thinks will be accessed the least.

Glyco's register allocator is spread over three \gs{nanopass} which perform the following steps, for the main program and each procedure separately:
\begin{enumerate}
	\item Discover the abstract locations that are used and the data types that they take.
	\item For each abstract location, determine where in the program or procedure it is defined or redefined with a value and where that value is used. The execution path between a definition and that definition's last use is a \textbf{liveness interval}, a period of time where the definition's value is considered \emph{live}.
	\item Find out which liveness intervals overlap with other liveness intervals. The locations involved in such overlapping intervals are considered to be \textbf{in conflict} with each other.
	\item Assign registers to abstract locations so that no two abstract locations are assigned the same register if they are in conflict with each other. If no register is available for an abstract location, allocate space on the call frame and assign it that location.
	
	Prioritise abstract locations with few conflicts when assigning registers as they're likely to maximise the number of abstract locations that can be assigned to a register.
\end{enumerate}

\paragraph{From ID (Inferred Declarations) to AL} An ID program is \lowered{} to an AL program by inferring a declaration for each abstract location used in the program and each of the program's procedures. Each declaration associates an abstract location with a data type. For example, the ID program
\lstinputlisting{Programs/buffer.id}
is \lowered{} to the following AL program:
\lstinputlisting{Programs/buffer.al}

\paragraph{From AL (Abstract Locations) to ALA} Similar to how the previous \g{nanopass} infers local declarations, the AL to ALA \g{lowering} infers static\footnote{As observed from the code itself, without running or simulating the program.} liveness and conflict information about the program, and associates it with every effect and predicate in an ALA program. It consists of two data structures: a liveness set and a conflict graph.

An effect's \textbf{liveness set at entry} is a set of locations that are \textbf{possibly live} right before the effect is executed. Every location that is not in the set is considered \textbf{definitely dead}.\footnote{We choose to explicitly qualify liveness with \enquote{possibly} or \enquote{definitely} because by Rice's theorem it is impossible to ascertain whether a value is actually live in all execution paths. Liveness is a property of a program: a definition's value may not ever be live if the effects using the value are never executed. Compilers (including Glyco) take a conservative approach and \emph{assume} that a value is live if they cannot rule out that it's dead. This heuristic may cause suboptimal register allocation due to excessive liveness intervals, but guarantees correctness by not accidentally assigning two live values to the same register. In contrast, when an effect overwrites a location's value (without using the previous value), we can be certain about the previous value being dead at the point of entering the effect.} An effect's \textbf{conflict graph at entry} is a undirected graph of locations with an edge connecting every pair of locations that are in conflict right before the effect is executed. An effect's \textbf{liveness set at exit} resp. \textbf{conflict graph at exit} is the next effect's liveness set at entry resp. conflict graph at entry.

The analysis algorithm derives an effect's liveness set and conflict graph \emph{at entry} from the effect's liveness set and conflict graph \emph{at exit} using the following 2 rules.

\begin{itemize}
	
	\item If an effect \textbf{defines} a location's value, the location is marked as (definitely) dead at entry and thus removed from the liveness set at entry. We know for certain that the location is not live right before the effect executes since its value is overwritten.
	
	Additionally, the newly defined location is in conflict with all locations that are in the liveness set at exit. The effect (possibly) starts a liveness interval for the newly defined location in the middle of liveness intervals of each location in the liveness set. These liveness intervals overlap; the conflict graph at entry is therefore updated with edges between the newly defined location and every location in the liveness set at exit.
	
	\item If an effect \textbf{uses} a location's value, the location is marked as (possibly) live at entry and is thus added to the liveness set at entry. An effect that defines and uses the same location's value, i.e., an assignment to itself, is considered to keep the location (possibly) live.
	
\end{itemize}

Since the liveness set and conflict graph at entry depend on the liveness set and conflict graph at exit, the algorithm traverses the program backwards, i.e., against the direction of execution and towards the beginning of the program or procedure. The algorithm starts with an empty initial liveness set and conflict graph, i.e., a \texttt{return} effect's liveness set and conflict graph at exit are empty.

\paragraph{Location coalescing} The number of locations in a program can often be reduced by merging locations that are assigned the same value and are not in conflict with each other. For example, \texttt{three} and \texttt{number} in
\lstinputlisting{Programs/coalescable.al}
can be coalesced to get
\lstinputlisting{Programs/coalesced.al}
thereby saving one \texttt{set} effect and making the liveness set and conflict graph smaller.

The location coalescing optimisation algorithm works as follows:
\begin{enumerate}
	\item Select a candidate pair that is involved in a \texttt{set} effect. The algorithm is done if there are no (non-rejected) candidate pairs.
	\item If the candidate locations are in conflict with each other, reject the pair and try another.
	\item Tentatively form the union of the location vertices in the conflict graph. If the degree of the merged vertex is equal to or larger than the number of available registers, reject the pair and try another. This conservative heuristic by \cite{briggs} ensures that the merged location will not require spilling (to the call frame) after merging if the individual locations themselves don't require spilling.
	\item Commit the union of the location vertices in the conflict graph, arbitrarily choose which location to retain, and remove the other location from the program by substituting it everywhere with the retained location. If the pair consists of a physical and an abstract location,\footnote{Usually a result of the CC to SV \g{nanopass} which puts arguments and results in dedicated registers.} retain the physical location.
	\item Repeat from Step 1.
\end{enumerate}

\paragraph{From ALA (Abstract Locations, Analysed) to CD} The \g{nanopass} from ALA to CD uses the conflict graph at entry of the program and of each procedure to determine an assignment of abstract locations to physical locations, and substitutes each abstract locations with its assigned physical location.

Register assignment is a graph colouring problem on the conflict graph where the colours are the available registers. No two connected locations in the conflict graph can be coloured with the same colour, i.e., no two locations that are in conflict can be assigned to the same register. The register assignment algorithm works as follows:
\begin{enumerate}
	\item Select an abstract location $L$ with the lowest degree and without an assigned physical location. The algorithm is done if there is no such location.
	\item Select an available register. If any abstract location already assigned to this register is in conflict with $L$, reject the register and try another. If no (non-rejected) register is available, spill the abstract location by assigning it a free location on the call frame.
	\item Repeat from Step 1.
\end{enumerate}

Unlike most algorithms in the compiler's \gs{nanopass}, this algorithm runs in $O(nm)$ time for $n$ locations and $m$ assignable registers,\footnote{Assuming that conflict graph queries are done in amortised constant time, as in Glyco.} which underlines the importance of minimising the number of abstract locations via optimisations such as location coalescing.

\section{Structured Jumps \& Branches} \label{sct:cd}
The final major abstractions over straight-line programs are conditionals (\texttt{if}-\texttt{then}-\texttt{else} effects), sequences (\texttt{do} effects), and procedures.

In CD, a \textbf{conditional} consists of a predicate, an affirmative branch, and a negative branch. Whenever the predicate evaluates to true, the affirmative branch is executed, otherwise the negative branch is executed. A \textbf{sequence} sequentially executes its contained effects. A \textbf{procedure} can be invoked with a \texttt{call} effect which updates the \texttt{cra} register with the address of the next effect, then jumps to the procedure's code. These three features make CD a block-structured programming language which the upcoming \gs{nanopass} remove to get to a form that can be readily translated into assembly.

\paragraph{From CD (Conditionals) to PR} The CD to PR \g{nanopass} flattens conditionals, sequences, and procedures into \gs{bblock}. A \textbf{\g{bblock}} is \glsdesc*{bblock}. A \g{bblock}'s effects are followed by a \textbf{continuation}, which is a jump, branch, or call. For example, the CD program
\lstinputlisting{Programs/ifproc.cd}
is \lowered{} to the PR program
\lstinputlisting{Programs/ifproc.pr}
\todo{Highlight corresponding parts and labels. Add flow diagram.}

\paragraph{From PR (Predicates) to BB} The next \g{il} BB does not support predicates so the \g{nanopass} maps predicates to appropriate continuations. For example, the above program is \lowered{} to the BB program
\lstinputlisting{Programs/ifproc.bb}
\todo{Highlight corresponding parts and labels.}

\paragraph{From BB (Basic Blocks) to FO} The final structural transformation linearises \gs{bblock} in BB programs to get an FO program with a single list of unlabelled and labelled effects.

The \g{nanopass} attempts to get an optimal placement of \gs{bblock}, i.e., an optimal trace, by juxtaposing successive blocks where possible. Unconditional jumps between juxtaposed blocks can be elided thereby avoiding the cost associated with jumps such as redundant instructions and pipeline stalls.

The above BB program becomes the following FO program:
\lstinputlisting{Programs/ifproc.fo}
\todo{Highlight corresponding parts and labels.}

\section{Basic Abstractions over Assembly} \label{sct:fo}
The last \gs{il} provide some useful basic abstractions over the CHERI-RISC-V instruction set.

\paragraph{From FO (Flexible Operands) to MM} FO effects accept input from several kinds of sources such as constants, registers, and (call) frame locations; and can produce results in registers or frame locations. Some source–destination combinations are not available as CHERI-RISC-V instructions. There is for instance no addition instruction that can load operands from memory or store a result in memory. There's also no subtraction instruction that takes an immediate minuend (first term).

To abstract this complexity away in FO and higher \gs{il}, the FO to MM \g{nanopass} inserts the necessary loads and stores and reorders operands to realise an effect using CHERI-RISC-V instructions in a lower \g{nanopass}.

\paragraph{From MM (Managed Memory) to RV} MM introduces the call stack and heap and operations on them such as call frame pushing and popping and buffer allocation.

The MM to RV \g{nanopass} translates call frame operations such as \texttt{pushFrame}, \texttt{popFrame}, \texttt{load}, and \texttt{store} into manipulations of the stack capability register \texttt{csp} and frame capability register \texttt{cfp}.

Buffer allocation is implemented using a dedicated heap capability register \texttt{ctp}. The heap capability points to the next free location on the heap and allocation increases the heap capability address — deallocation is not supported.

\paragraph{From RV (CHERI-RISC-V) to S (CHERI-RISC-V Assembly)} An RV program consists of CHERI-RISC-V instructions. The RV to S \g{nanopass} serialises these instructions. For example, \texttt{copyWord(destination: a0, source: a1)} instruction is serialised as \hbox{\texttt{mv a0, a1}}.

\paragraph{From S to ELF} The final step of the compiler pipeline is assembling and linking. These two steps are delegated to Clang from the CHERI-LLVM compiler toolchain.\footnote{This last step is unrelated to the research problem, hence this dependency on LLVM.} The result is an ELF file that, depending on the compilation target, can be executed in either the Sail-based CHERI-RISC-V emulator or in CheriBSD.

\biblio{}
\onlyinsubfile{\glsaddall\printglossaries}
\end{document}
