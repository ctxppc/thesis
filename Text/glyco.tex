\documentclass[main.tex]{subfiles}
\begin{document}
\onlyinsubfile{\mainmatter{}}

\chapter{Glyco: A Nanopass Compiler for CHERI-RISC-V}

Glyco\footnote{From the Greek term $\gamma\lambda\upsilon\kappa{}o$ meaning \enquote{sweet}, alluding to the taste of a wild cherry.} is a compiler targeting the CHERI-RISC-V architecture, producing software running on CheriBSD systems and on a Sail-based emulator of the CHERI-RISC-V ISA.

We begin by giving a concise description of the nanopass compiler design, which is used for Glyco. We then describe the design \& implementation of the base compiler, a compiler that emits CHERI-RISC-V instructions but has almost no additional features taking advantage of the capability machine proper. Later chapters discuss extensions and changes to this first version of the compiler.

\section{Background: Nanopass Compilers}
Glyco is built following a \emph{nanopass} compiler design, described in the context of compiler education by several authors such as \cite{educomp} and in the context of commercial compiler development by authors such as \cite{commcomp}. A nanopass compiler consists of numerous small passes, so-called \emph{\glspl{nanopass}}, which translate one \emph{\il{}} to another. Source code is parsed into the compilerâ€™s first \il{}, which is then translated via \glspl{nanopass} through different \ils{}, ending up in the compiler's final \il{}. This final \il{} contains a string representation of the assembly code that is fed to the Clang compiler from the LLVM compiler toolchain for building \& linking an executable ELF file. This last step is unrelated to the research problem, hence this dependency on LLVM.

The nanopass design allows the compiler engineer to design and implement their compiler \emph{by iterated abstraction}. A simplified description follows. The engineer first chooses a target language (usually a machine language such as x86-64 or indeed CHERI-RISC-V) and determines an abstraction over it. The engineer then defines an \il{} that implements that abstraction as well as a \gls{nanopass} which transforms programs written in the new \il{} to the target language. The compiler engineer then repeats this process, this time abstracting over the \il{} with a new \il{} and \gls{nanopass}. This process goes on until a level of abstraction has been reached that can either be directly used as a source language (by human users), or be easily produced by parser actions.

An important benefit of the nanopass approach is each new iteration begins and ends with a working compiler. After each iteration, users can start writing and compiling programs in the new \il{} and unit tests can be written that ensure that the new \gls{nanopass} produces the expected transformations. For experimental architectures such as CHERI-RISC-V, this also means that designers can experiment more quickly with new ideas, something that may be harder to do on a full-fledged production compiler such as Clang.

\section{Basic Abstractions over Assembly}
The first version of Glyco defines 17 \ils{}. Each \il{} has a name and corresponding abbreviation, usually named after the abstraction it provides over the \lowerlang{}, and are defined by a context-free grammar. Many of these \ils{} are adapted from the educational compiler by \cite{compcourse}.

The first 4 \ils{} (S through FO) provide some basic abstractions over the CHERI-RISC-V assembly language that are useful in higher abstractions. Just like programs written in assembly, programs in the 4 languages are merely sequences of (possibly labelled) instructions or effects.

\paragraph{CHERI-RISC-V Assembly (S)} The ground language is a wrapper around the assembly representation of the program, as can been seen in \cref{bnf:s}. This language is compiled by adding some runtime code to this assembly before passing it to Clang.
\begin{figure}[ht]
	\small
	\begin{grammar}
		<Program> ::= (assembly: <String>)
	\end{grammar}
	\caption{The grammar for S.}
	\label{bnf:s}
\end{figure}

\paragraph{CHERI-RISC-V (RV)} The next \il{} provides a more structured, i.e., non-textual, representation of the assembly language and is adapted from \texttt{paren-x86} in \cite{compcourse} to the CHERI-RISC-V ISA. Every instruction in this language corresponds with an instruction or pseudo-instruction in the assembly language, except for the special \emph{labelled} instruction which decorates the wrapped instruction with a label. An abridged grammar can be seen in \Cref{bnf:rv}.

One important deviation from \cite{compcourse} across the whole compiler pipeline is the support for multiple data types and the presence of capability-aware instructions in Glyco, due to CHERI-RISC-V having a different instruction set operating on capabilities than on non-capability data. For instance, the \texttt{offsetCapability} instruction cannot be replicated using addition (e.g., \texttt{\&array[5] + 2}) due to CHERI's capability provenance security property, whereas pointer arithmetic is exactly how pointers are offset in an architecture where pointers and integers (of the right bitwidth) are represented using the same machine data type.

\begin{figure}[ht]
	\small
	\begin{grammar}
		
		<Program> ::= (<Instructions>)
		
		<Instructions> ::= <Instruction> | <Instruction> <Instructions>
		
		<Instruction> ::= copyWord(destination: <Register>, source: <Register>)
			\alt copyCapability(destination: <Register>, source: <Register>)
			\alt computeWithRegister(operation: <BinaryOperator>, rd: <Register>, rs1: <Register>, rs2: <Register>)
			\alt computeWithImmediate(operation: <BinaryOperator>, rd: <Register>, rs1: <Register>, imm: <Int>)
			\alt loadSignedWord(destination: <Register>, address: <Register>)
			\alt storeSignedWord(source: <Register>, address: <Register>)
			\alt offsetCapability(destination: <Register>, source: <Register>, offset: <Register>)
			\alt branch(rs1: <Register>, relation: <BranchRelation>, rs2: <Register>, target: <Label>)
			\alt call(target: <Label>)
			\alt jump(target: <Label>)
			\alt labelled(<Label>, <Instruction>)
			\alt $\cdots$
			
		<Register> ::= zero | ra | sp | fp | t0 | t1 | t2 | s1 | $\cdots$
		
	\end{grammar}
	\caption{Abridged grammar for RV.}
	\label{bnf:rv}
\end{figure}

\paragraph{Managed Memory (MM)} This language introduces abstractions over memory operations, hence its name, as well as effects that operate on it, and restricts memory operations to either the call frame or allocated buffers. Its main purpose is to hide the stack and frame capability registers early on, i.e., from most abstractions in the compiler. An abridged grammar is shown in \cref{bnf:mm}.

MM is an adaptation of \texttt{paren-x86-mops} in \cite{compcourse} with several deviations. Since the stack and frame capability registers are not available in higher \ils{}, the load and store effects for data on the call frame are different from those for data in an allocated buffer. Additionally, MM provides effects for pushing and popping a buffer on the call stack. Another deviation is the computation effect, which can write its result to a different register than the one used for one of its operands and that it cannot read directly from memory, both due to the RISC-V ISA. Finally, MM introduces statically allocated buffers, a feature not present in the \cite{compcourse} compiler.

\begin{figure}[ht]
	\small
	\begin{grammar}
		
		<Program> ::= (<Effects>)
		
		<Effects> ::= <Effect> | <Effect> <Effects>
		
		<Effect> ::= copy(<DataType>, into: <Register>, from: <Register>)
			\alt compute(<Register>, <BinaryExpression>)
			\alt load(<DataType>, into: <Register>, from: <Frame.Location>)
			\alt store(<DataType>, into: <Frame.Location>, from: <Register>)
			\alt createBuffer(bytes: <Int>, capability: <Register>, onFrame: <Bool>)
			\alt loadElement(<DataType>, into: <Register>, buffer: <Register>, offset: <Register>)
			\alt storeElement(<DataType>, buffer: <Register>, offset: <Register>, from: <Register>)
			\alt pushFrame(<Frame>)
			\alt popFrame
			\alt $\cdots$
		
		<DataType> ::= u8 | s32 | cap
		
		<BinaryExpression> ::= registerRegister(<Register>, <BinaryOperator>, <Register>)
			\alt registerImmediate(<Register>, <BinaryOperator>, <Int>)
		
		<Frame> ::= (allocatedByteSize: <Int>)
		
		<Frame.Location> ::= (offset: <Int>)
		
		<Bool> ::= true | false
		
	\end{grammar}
	\caption{Abridged grammar for MM.}
	\label{bnf:mm}
\end{figure}

\paragraph{Flexible Operands (FO)} The next abstraction removes the load and store effects on the call frame and instead allows the remaining effects to refer directly to a location on the call frame besides referring to a register. This is an adaptation from \texttt{para-asm-lang} in \cite{compcourse} with the same deviations as in MM. An abridged grammar is presented in \Cref{bnf:fo}.

\begin{figure}[ht]
	\small
	\begin{grammar}
		
		<Program> ::= (<Effects>)
		
		<Effect> ::= set(<DataType>, <Location>, to: <Source>)
			\alt compute(<Source>, <BinaryOperator>, <Source>, to: <Location>)
			\alt allocateBuffer(bytes: <Int>, into: <Location>)
			\alt getElement(<DataType>, of: <Location>, offset: <Source>, to: <Location>)
			\alt setElement(<DataType>, of: <Location>, offset: <Source>, to: <Source>)
			\alt branch(to: <Label>, <Source>, <BranchRelation>, <Source>)
			\alt $\cdots$
		
		<Location> ::= register(<Register>) | frameCell(<Frame.Location>)
		
		<Source> ::= location(<Location>) | immediate(<Int>)
		
	\end{grammar}
	\caption{Abridged grammar for FO.}
	\label{bnf:fo}
\end{figure}

\section{Structured Jumps \& Branches}
The next 3 \ils{} (BB through CD) constrain jumps \& branches so that they're easier to reason about in optimisations and higher abstracts.

\paragraph{Basic Blocks (BB)} Basic blocks are sequences of effects which always execute together, or more specifically, can only be entered at the start of the sequence and only exited at the end of the sequence. BB defines a program to be a set of basic blocks, where each block has a label, contains a sequence of effects that aren't jumps or branches, and ends with a jump or branch. The initial block is named using a dedicated program entry label. The \il{} adapts \texttt{block-asm-lang} from \cite{compcourse} with similar deviations from FO, including a special \texttt{call} continuation. An abridged grammar is shown in \Cref{bnf:bb}.

\begin{figure}[ht]
	\small
	\begin{grammar}
		
		<Program> ::= (<Blocks>)
		
		<Blocks> ::= <Block> <Blocks> | <Block>
		
		<Block> ::= (name: <Label>, do: <Effects>, then: <Continuation>)
		
		<Continuation> ::= continue(to: <Label>)
			\alt branch(<Source>, <BranchRelation>, <Source>, then: <Label>, else: <Label>)
			\alt call(<Label>, returnPoint: <Label>)
			\alt return
		
		<Effect> ::= set(<DataType>, <Location>, to: <Source>)
			\alt compute(<Source>, <BinaryOperator>, <Source>, to: <Location>)
			\alt allocateBuffer(bytes: <Int>, into: <Location>)
			\alt getElement(<DataType>, of: <Location>, offset: <Source>, to: <Location>)
			\alt setElement(<DataType>, of: <Location>, offset: <Source>, to: <Source>)
			\alt $\cdots$
		
	\end{grammar}
	\caption{Abridged grammar for BB.}
	\label{bnf:bb}
\end{figure}

\paragraph{Predicates (PR)} The next language removes the fixed relation specification from \texttt{branch} continuations and replaces it with a basic predicate syntax. It adapts \texttt{block-pred-lang} from \cite{compcourse} with similar deviations from BB. An abridged grammar is presented in \Cref{bnf:pr}.

\begin{figure}[ht]
	\small
	\begin{grammar}
		
		<Program> ::= (<Blocks>)
		
		<Block> ::= (name: <Label>, do: <Effects>, then: <Continuation>)
		
		<Continuation> ::= continue(to: <Label>)
			\alt branch(if: <Predicate>, then: <Label>, else: <Label>)
			\alt call(<Label>, returnPoint: <Label>)
			\alt return
			
		<Predicate> ::= constant(<Bool>)
			\alt not(<Predicate>)
			\alt relation(<Source>, <BranchRelation>, <Source>)
			
		<Bool> ::= false | true
		
	\end{grammar}
	\caption{Abridged grammar for PR.}
	\label{bnf:pr}
\end{figure}

\paragraph{Conditionals (CD)} With primitive predicates now available in PR, the next abstraction extends their power by allowing \texttt{if(_:then:else:)} conditionals in predicates and effects alike, thereby moulding effects into tree structures. CD includes support for procedures, which are modelled as an (effect) tree for each procedure, as well as support for (recursively) invoking them, which is modelled with the \texttt{call} and \texttt{return} effects. Control flows in pre-order, skipping nodes from false branches in conditionals, with control temporarily flowing to another (effect) tree when encountering a \texttt{call} effect and back to the previous tree when encountering a \texttt{return} effect.

With these more deterministic control flows, CD can abstract basic blocks away. A program in CD consists of a main effect and zero or more procedures. Each procedure has a unique name and a main effect. An abridged grammar is presented in \Cref{bnf:cd}.

CD is a partial adaptation of \texttt{nested-asm-lang} from \cite{compcourse}. CD does not define a \texttt{return-point} effect and instead relies on the \texttt{call} and \texttt{return} effects to push and pop a return address on the call stack. The underlying language defines a \texttt{call} effect which cannot be implemented using a combination of \texttt{jump} and other effects.

\begin{figure}[ht]
	\small
	\begin{grammar}
		
		<Program> ::= (<Effect>, procedures: <Procedures>)
		
		<Procedures> ::= <Procedure> <Procedures> | <Procedure>
		
		<Procedure> ::= (<Label>, in: <Effect>)
		
		<Predicate> ::= constant(<Bool>)
			\alt relation(<Source>, <BranchRelation>, <Source>)
			\alt if(<Predicate>, then: <Predicate>, else: <Predicate>)
			\alt do(<Effects>, then: <Predicate>)
		
		<Effect> ::= do(<Effects>)
			\alt set(<DataType>, <Location>, to: <Source>)
			\alt compute(<Source>, <BinaryOperator>, <Source>, to: <Location>)
			\alt allocateBuffer(bytes: <Int>, into: <Location>)
			\alt getElement(<DataType>, of: <Location>, offset: <Source>, to: <Location>)
			\alt setElement(<DataType>, of: <Location>, offset: <Source>, to: <Source>)
			\alt call(<Label>)
			\alt $\cdots$
		
	\end{grammar}
	\caption{Abridged grammar for CD.}
	\label{bnf:cd}
\end{figure}

\section{Abstract Locations}
The next 2 \ils{}, AL and ALA, introduce an abstraction over physical locations, whether on the call frame or in registers. The two \ils{} are tightly coupled.

% TODO

\section{A Conventional Calling Convention}
% TODO

\section{An Expression Language}
% TODO

\biblio{}
\onlyinsubfile{\glsaddall\printglossaries}
\end{document}
